import apriltag
from abc import abstractmethod
import numpy as np
import os
import cv2
import itertools

def grayscale_8bit(image):
    """
    Convert any OpenCV image to single-channel 8-bit grayscale.
    Handles different input types and normalizes white to 255 where necessary.
    """
    if image is None:
        raise ValueError("Input image is None")
    # Convert multi-channel images to grayscale
    if len(image.shape) == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # Convert image to 8-bit if it's not already
    if image.dtype == np.uint8:
        return image  # Already 8-bit grayscale
    # Normalize different white values to 255
    elif image.dtype == np.uint16:
        image = (image / 255).astype(np.uint8)  # Normalize 16-bit white (65535) to 8-bit (255)
    elif image.dtype == np.float32 or image.dtype == np.float64:
        image = (image * 255).clip(0, 255).astype(np.uint8)  # Normalize floating point white (1.0) to 8-bit (255)
    return image
# end grayscale_8bit

class EventProcessor():
    '''
    EventProcessors process events.
    events are dictionaries where each the value of each key is a "property" of that event.
    Overload method process to process an event. The overloaded function must return an event or None.

    Chain event processors together with the add_event_processor method.
    A public method "process" concatenates all the properties generated by method process with 
        the properties passed to "process" and propagates the result to all the
        chained event processors
    '''
    def __init__(self):
        self.most_recent_event= None
        self.event_processor_list = {}
    # end method __init__

    def add_event_processor(self, name, event_processor):
        self.event_processor_list[name] = event_processor
    # end method add_event_processor

    @abstractmethod
    def process(self, event: dict):
        if event is None:
            return
        if not isinstance (event, dict):
            raise Exception(f"The event should be a dictionary type. Instead it's a {type(event).__name__}: {event}")
    # end method process

    def propagate(self, event: dict, processed_event: dict):
        if not isinstance (event, dict):
            raise Exception(f"The event should be a dictionary type. Instead it's a {type(event).__name__}: {event}")
        if processed_event is None:
            return
        if not isinstance(processed_event, dict):
            raise Exception(f"The processd_event from a {type(self).__name__} is malformed should be a dictionary type. Instead it's a {type(processed_event)}: {processed_event}")
        processed_event = event | processed_event
        self.most_recent_event = processed_event
        for ep in self.event_processor_list.values():
            ep.process(processed_event)
    # end method propagate
# end class EventProcessor

def expect_property(property_name: str, event: dict) -> bool:
    '''
    Guarantees a property exists in an event
    '''
    if not isinstance (event, dict):
        raise Exception(f"The event should be a dictionary type. Instead it's a {type(event).__name__}: {event}")
    if not isinstance (property_name, str):
        raise Exception(f"The property_name should be a dictionary type. Instead it's a {type(property_name)}: {property_name}")
    if property_name not in event:
        raise Exception(f"Expecting an event with the property '{property_name}', but none was given in the event: {event}")
# end method expect_property

class Camera(EventProcessor):
    '''
    Creates the following properties in an event:
        "camera_image":        a cv2.Mat captured at time "time" if the image exists
        "camera_matrix":       the camera's intrinsic matrix
    '''
    def __init__(self):
        super(Camera, self).__init__()
        self.global_properties = {
            "camera_matrix": np.array(
                [[736, 0,   640],
                 [0,   736, 400],
                 [0,   0,   1  ]], 
                dtype=np.float32
            )
        }
        self.sequence_path = "renders/"
        self.image_files = sorted([f for f in os.listdir(self.sequence_path) if f.endswith('.jpg')])
    # end method __init__

    def process(self, event: dict):
        super(Camera, self).process(event) # check that nothing suspicious is happening
        # the time of the simulation: an integer from 0 to the number of images in "renders/"
        expect_property("time", event)
        time = event["time"]
        image = cv2.imread(os.path.join(self.sequence_path, self.image_files[time]))
        processed_event = self.global_properties | {
            "camera_image": image
        }
        self.propagate(event, processed_event)
    # end method method process
# end class Camera

class AprilTagDetector(EventProcessor):
    '''
    Creates the following properties in an event:
        "apriltag_info"     an apriltag.Detection object
        "apriltag_corners"  a 4-long numpy array of 2-long vectors.
                                each vector is the coordinates of a corner in image space.
                                element 0:    top left
                                element 1: bottom left
                                element 2: bottom right
                                element 3:    top right (TODO confirm)
        "apriltag_id"       the tag ID, unique to the tag in the playing field
    '''
    def __init__(self):
        super(AprilTagDetector, self).__init__()
        options = apriltag.DetectorOptions(families="tag36h11")
        self.apriltag_detector = apriltag.Detector(options)
    # end method __init__


    def process(self, event: dict):
        expect_property("camera_image", event)
        image_gray = grayscale_8bit(event["camera_image"])
        detected_apriltags = self.apriltag_detector.detect(image_gray)
        for detected_apriltag in detected_apriltags:
            apriltag_corners = corners = np.array(detected_apriltag.corners, dtype=np.float32)
            if corners.shape[0] < 4: continue
            self.propagate(event, {
                "apriltag_info"    : detected_apriltag,
                "apriltag_corners" : apriltag_corners,
                "apriltag_id"      : detected_apriltag.tag_id
            })
    # end method process
# end class AprilTagDetector

def apriltag_coordinates_to_image_coordinates(event, xyz_in_apriltag_coordinates):
    """
    Given relative XYZ coordinates in April Tag space, returns the point projected in image space
    Args:
    - event - an Event. Must contain the following properties:
        "apriltag_corners" (np.array): 2D image coordinates of the AprilTag.
        "camera_matrix"    (np.array): the camera's intrinsic matrix
    - xyz_in_apriltag_coordinates (list): XYZ coordinates relative to the tag's frame.
    Returns:
    - best_image_point (tuple): xyz_in_apriltag_coordinates in image coordinates.
    """
    expect_property("apriltag_corners", event)
    expect_property("camera_matrix",    event)
    # Define 3D points of the cube (global)
    square_points = np.array([[0, 0, 0], [1, 0, 0], [1, 1, 0], [0, 1, 0]], dtype=np.float32)
    success, rvecs, tvecs, _ = cv2.solvePnPGeneric(
        objectPoints=square_points, 
        imagePoints=event["apriltag_corners"], 
        cameraMatrix=event["camera_matrix"], 
        distCoeffs=np.zeros(4, dtype=np.float32),  # Assuming no distortion
        flags=cv2.SOLVEPNP_IPPE
    )
    if not success or len(rvecs) == 0:
        return None
    most_left_point = None
    most_left_x = float("inf")
    most_right_point = None
    most_right_x = float("-inf")
    # Find the leftmost evaluated point. This improves temporal consistency
    for rvec, tvec in zip(rvecs, tvecs):
        xy_in_image_coordinates, _ = cv2.projectPoints(
            objectPoints=np.array([xyz_in_apriltag_coordinates], dtype=np.float32), 
            rvec=rvec, 
            tvec=tvec, 
            cameraMatrix=event["camera_matrix"], 
            distCoeffs=np.zeros(4, dtype=np.float32),  # Again, assuming no distortion
        )
        xy_in_image_coordinates = tuple(map(int, xy_in_image_coordinates.ravel()))
        if xy_in_image_coordinates[0] < most_left_x:
            most_left_x = xy_in_image_coordinates[0]
            most_left_point = xy_in_image_coordinates
        if xy_in_image_coordinates[0] > most_right_x:
            most_right_x = xy_in_image_coordinates[0]
            most_right_point = xy_in_image_coordinates
    c = event["apriltag_corners"]

    def weighted_tuple_interpolation(tuple_a, tuple_b, value_a, value_b, smoothness=5):
        """
        Interpolates between two 2-tuples based on the given values.
        
        Args:
            tuple_a (tuple): First tuple (x1, y1).
            tuple_b (tuple): Second tuple (x2, y2).
            value_a (float): Weight for tuple_a.
            value_b (float): Weight for tuple_b.
            smoothness (float): Controls how gradually the interpolation shifts. Default is 5.
        
        Returns:
            tuple: Interpolated (x, y) tuple.
        """
        # Compute a softmax-like weight distribution
        weight_a = np.exp(smoothness * value_a)
        weight_b = np.exp(smoothness * value_b)
        # Normalize weights
        total_weight = weight_a + weight_b
        weight_a /= total_weight
        weight_b /= total_weight
        # Compute the interpolated tuple
        interpolated_x = weight_a * tuple_a[0] + weight_b * tuple_b[0]
        interpolated_y = weight_a * tuple_a[1] + weight_b * tuple_b[1]
        return (int(interpolated_x), int(interpolated_y))
    # end inner function weighted_tuple_interpolation
    
    tag_left_edge_size  = c[3][1] - c[0][1]
    tag_right_edge_size = c[2][1] - c[1][1]
    use_left_point = tag_left_edge_size > tag_right_edge_size
    best_image_point = most_left_point if use_left_point else most_right_point
    best_image_point = weighted_tuple_interpolation(
        most_left_point,
        most_right_point,
        tag_left_edge_size,
        tag_right_edge_size,
        5
    )
    return best_image_point
# end function apriltag_coordinates_to_image_coordinates

class ReefDetector(EventProcessor):
    def __init__(self, id):
        super(ReefDetector, self).__init__()
        self.id = id # The April Tag ID to look for
        # The positions of the reef slots to look for coral
        x = (-0.4, 1.6); y = (-1.8, -4.2, -6.8); z = (1.4,)
        self.reef_positions_relative_to_apriltag = list(itertools.product(x,y,z))
        # Same for algae
        ax = (0.6,); ay = (-3.3, -5.8); az = (0.8,)
        self.algae_positions_relative_to_apriltag = list(itertools.product(ax,ay,az))
    # end method __init__

    def process(self, event: dict):
        # the time of the simulation: an integer from 0 to the number of images in "renders/"
        expect_property("apriltag_id", event)
        # Ignore other April Tags
        if event["apriltag_id"] != self.id:
            return
        self.propagate(event, {
            "reef_detector_temporary_position": 
                [apriltag_coordinates_to_image_coordinates(
                    event=event, 
                    xyz_in_apriltag_coordinates=pos
                ) for pos in self.reef_positions_relative_to_apriltag],
            "algae_detector_temporary_position": 
                [apriltag_coordinates_to_image_coordinates(
                    event=event, 
                    xyz_in_apriltag_coordinates=pos
                ) for pos in self.algae_positions_relative_to_apriltag],
        })

        # When done processing the event, draw the positions on the screen for debugging
        for c in self.most_recent_event["reef_detector_temporary_position"]:
            cv2.circle(
                      img = r.most_recent_event["camera_image"],
                   center = c,
                   radius = 8,
                    color = (0,0,255), # red
                thickness = -1     # fill in
            )
        for c in self.most_recent_event["algae_detector_temporary_position"]:
            cv2.circle(
                    img = r.most_recent_event["camera_image"],
                 center = c,
                 radius = 8,
                  color = (255,255,0), # red
              thickness = -1     # fill in
            )
    # end method process
# end class ReefDetector

class EPTemplate(EventProcessor):
    def __init__(self):
        super(EPTemplate, self).__init__()
    # end method __init__

    def process(self, event: dict):
        # the time of the simulation: an integer from 0 to the number of images in "renders/"
        expect_property("time", event)
        self.propagate(event, {
            
        })
    # end method process
# end class EPTemplate


# Worldbuilding
c = Camera()
a = AprilTagDetector()
r = ReefDetector(10)
# World linking
c.add_event_processor(name="Apriltag detector", event_processor=a)
a.add_event_processor(name="Reef detector",     event_processor=r)
# Launch the world simulation
event = {
    "time": 130
}

def update_time(val):
    """
    Callback on slider change.
    """
    global c
    global r
    global event
    event["time"] = val
    c.process(event)  # Reprocess event with new time
    img = r.most_recent_event["camera_image"].copy()  # Get updated image
    cv2.imshow("image", img)  # Show updated image

# Create OpenCV window
cv2.namedWindow("image")

# Create a trackbar for adjusting time
cv2.createTrackbar("Time", "image", 0, 250, update_time)  # Adjust max value as needed

# Initialize by calling the function once
update_time(event["time"])

# Wait for user interaction
cv2.waitKey(0)
cv2.destroyAllWindows()